{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH4XmErYj5wm"
      },
      "source": [
        "# Lab 10"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Aim:** To implement ResNet101 CNN Architecture"
      ],
      "metadata": {
        "id": "99OhKk9-XRSr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ORj09gnrj5wp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Subset\n",
        "\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NnT0sZIwj5wu"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "RANDOM_SEED = 1\n",
        "LEARNING_RATE = 0.01\n",
        "NUM_EPOCHS = 25\n",
        "\n",
        "# Architecture\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "GRAYSCALE = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKSxwgLyNiyo",
        "outputId": "b8e90118-d77a-4eef-d08d-b57533436212"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 12606907.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image batch dimensions: torch.Size([128, 3, 32, 32])\n",
            "Image label dimensions: torch.Size([128])\n",
            "Image batch dimensions: torch.Size([128, 3, 32, 32])\n",
            "Image label dimensions: torch.Size([128])\n",
            "Image batch dimensions: torch.Size([128, 3, 32, 32])\n",
            "Image label dimensions: torch.Size([128])\n"
          ]
        }
      ],
      "source": [
        "train_indices = torch.arange(0, 49000)\n",
        "valid_indices = torch.arange(49000, 50000)\n",
        "\n",
        "\n",
        "train_and_valid = datasets.CIFAR10(root='data',\n",
        "                                   train=True,\n",
        "                                   transform=transforms.ToTensor(),\n",
        "                                   download=True)\n",
        "\n",
        "train_dataset = Subset(train_and_valid, train_indices)\n",
        "valid_dataset = Subset(train_and_valid, valid_indices)\n",
        "\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root='data',\n",
        "                                train=False,\n",
        "                                transform=transforms.ToTensor())\n",
        "\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          num_workers=8,\n",
        "                          shuffle=True)\n",
        "\n",
        "valid_loader = DataLoader(dataset=valid_dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          num_workers=8,\n",
        "                          shuffle=False)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_dataset,\n",
        "                         batch_size=BATCH_SIZE,\n",
        "                         num_workers=8,\n",
        "                         shuffle=False)\n",
        "\n",
        "# Checking the dataset\n",
        "for images, labels in train_loader:\n",
        "    print('Image batch dimensions:', images.shape)\n",
        "    print('Image label dimensions:', labels.shape)\n",
        "    break\n",
        "\n",
        "for images, labels in test_loader:\n",
        "    print('Image batch dimensions:', images.shape)\n",
        "    print('Image label dimensions:', labels.shape)\n",
        "    break\n",
        "\n",
        "for images, labels in valid_loader:\n",
        "    print('Image batch dimensions:', images.shape)\n",
        "    print('Image label dimensions:', labels.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ftjK0TGlNiyp"
      },
      "outputs": [],
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes, grayscale):\n",
        "        self.inplanes = 64\n",
        "        if grayscale:\n",
        "            in_dim = 1\n",
        "        else:\n",
        "            in_dim = 3\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_dim, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1, padding=2)\n",
        "        #self.fc = nn.Linear(2048 * block.expansion, num_classes)\n",
        "        self.fc = nn.Linear(2048, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, (2. / n)**.5)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        #x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        logits = self.fc(x)\n",
        "        probas = F.softmax(logits, dim=1)\n",
        "        return logits, probas\n",
        "\n",
        "\n",
        "\n",
        "def resnet101(num_classes, grayscale):\n",
        "    \"\"\"Constructs a ResNet-101 model.\"\"\"\n",
        "    model = ResNet(block=Bottleneck,\n",
        "                   layers=[3, 4, 23, 3],\n",
        "                   num_classes=NUM_CLASSES,\n",
        "                   grayscale=grayscale)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_lza9t_uj5w1"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(RANDOM_SEED)\n",
        "model = resnet101(NUM_CLASSES, GRAYSCALE)\n",
        "model.to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dzh3ROmRj5w7",
        "outputId": "e8efdc7e-e36f-45dc-d3a7-d44589f71292",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001/025 | Batch 000/383 | Cost: 2.7585\n",
            "Epoch: 001/025 | Batch 120/383 | Cost: 3.7965\n",
            "Epoch: 001/025 | Batch 240/383 | Cost: 2.2732\n",
            "Epoch: 001/025 | Batch 360/383 | Cost: 2.0641\n",
            "Epoch: 001/025 Train Acc.: 29.08% | Validation Acc.: 30.80%\n",
            "Time elapsed: 1.30 min\n",
            "Epoch: 002/025 | Batch 000/383 | Cost: 1.8997\n",
            "Epoch: 002/025 | Batch 120/383 | Cost: 1.6565\n",
            "Epoch: 002/025 | Batch 240/383 | Cost: 1.6737\n",
            "Epoch: 002/025 | Batch 360/383 | Cost: 1.7384\n",
            "Epoch: 002/025 Train Acc.: 41.41% | Validation Acc.: 41.20%\n",
            "Time elapsed: 2.57 min\n",
            "Epoch: 003/025 | Batch 000/383 | Cost: 1.4844\n",
            "Epoch: 003/025 | Batch 120/383 | Cost: 1.5908\n",
            "Epoch: 003/025 | Batch 240/383 | Cost: 1.4972\n",
            "Epoch: 003/025 | Batch 360/383 | Cost: 1.4840\n",
            "Epoch: 003/025 Train Acc.: 48.25% | Validation Acc.: 49.10%\n",
            "Time elapsed: 3.84 min\n",
            "Epoch: 004/025 | Batch 000/383 | Cost: 1.1930\n",
            "Epoch: 004/025 | Batch 120/383 | Cost: 1.4712\n",
            "Epoch: 004/025 | Batch 240/383 | Cost: 1.4109\n",
            "Epoch: 004/025 | Batch 360/383 | Cost: 1.2905\n",
            "Epoch: 004/025 Train Acc.: 55.51% | Validation Acc.: 53.20%\n",
            "Time elapsed: 5.13 min\n",
            "Epoch: 005/025 | Batch 000/383 | Cost: 1.2403\n",
            "Epoch: 005/025 | Batch 120/383 | Cost: 1.1947\n",
            "Epoch: 005/025 | Batch 240/383 | Cost: 1.3734\n",
            "Epoch: 005/025 | Batch 360/383 | Cost: 1.0939\n",
            "Epoch: 005/025 Train Acc.: 61.72% | Validation Acc.: 59.40%\n",
            "Time elapsed: 6.41 min\n",
            "Epoch: 006/025 | Batch 000/383 | Cost: 1.0849\n",
            "Epoch: 006/025 | Batch 120/383 | Cost: 1.0589\n",
            "Epoch: 006/025 | Batch 240/383 | Cost: 1.4794\n",
            "Epoch: 006/025 | Batch 360/383 | Cost: 1.1895\n",
            "Epoch: 006/025 Train Acc.: 61.20% | Validation Acc.: 59.20%\n",
            "Time elapsed: 7.69 min\n",
            "Epoch: 007/025 | Batch 000/383 | Cost: 1.1170\n",
            "Epoch: 007/025 | Batch 120/383 | Cost: 1.0913\n",
            "Epoch: 007/025 | Batch 240/383 | Cost: 1.1495\n",
            "Epoch: 007/025 | Batch 360/383 | Cost: 0.9294\n",
            "Epoch: 007/025 Train Acc.: 68.34% | Validation Acc.: 66.30%\n",
            "Time elapsed: 8.98 min\n",
            "Epoch: 008/025 | Batch 000/383 | Cost: 0.8882\n",
            "Epoch: 008/025 | Batch 120/383 | Cost: 0.9053\n",
            "Epoch: 008/025 | Batch 240/383 | Cost: 1.0006\n",
            "Epoch: 008/025 | Batch 360/383 | Cost: 0.7615\n",
            "Epoch: 008/025 Train Acc.: 74.02% | Validation Acc.: 70.10%\n",
            "Time elapsed: 10.27 min\n",
            "Epoch: 009/025 | Batch 000/383 | Cost: 0.7237\n",
            "Epoch: 009/025 | Batch 120/383 | Cost: 1.0414\n",
            "Epoch: 009/025 | Batch 240/383 | Cost: 0.8668\n",
            "Epoch: 009/025 | Batch 360/383 | Cost: 0.7295\n",
            "Epoch: 009/025 Train Acc.: 78.16% | Validation Acc.: 71.40%\n",
            "Time elapsed: 11.56 min\n",
            "Epoch: 010/025 | Batch 000/383 | Cost: 0.7486\n",
            "Epoch: 010/025 | Batch 120/383 | Cost: 0.8835\n",
            "Epoch: 010/025 | Batch 240/383 | Cost: 0.7277\n",
            "Epoch: 010/025 | Batch 360/383 | Cost: 0.8684\n",
            "Epoch: 010/025 Train Acc.: 74.77% | Validation Acc.: 69.10%\n",
            "Time elapsed: 12.84 min\n",
            "Epoch: 011/025 | Batch 000/383 | Cost: 0.6268\n",
            "Epoch: 011/025 | Batch 120/383 | Cost: 0.6856\n",
            "Epoch: 011/025 | Batch 240/383 | Cost: 0.7181\n",
            "Epoch: 011/025 | Batch 360/383 | Cost: 0.5709\n",
            "Epoch: 011/025 Train Acc.: 78.31% | Validation Acc.: 72.00%\n",
            "Time elapsed: 14.12 min\n",
            "Epoch: 012/025 | Batch 000/383 | Cost: 0.6416\n",
            "Epoch: 012/025 | Batch 120/383 | Cost: 0.7250\n",
            "Epoch: 012/025 | Batch 240/383 | Cost: 0.7191\n",
            "Epoch: 012/025 | Batch 360/383 | Cost: 0.6804\n",
            "Epoch: 012/025 Train Acc.: 81.89% | Validation Acc.: 72.30%\n",
            "Time elapsed: 15.41 min\n",
            "Epoch: 013/025 | Batch 000/383 | Cost: 0.5234\n",
            "Epoch: 013/025 | Batch 120/383 | Cost: 0.7396\n",
            "Epoch: 013/025 | Batch 240/383 | Cost: 0.5967\n",
            "Epoch: 013/025 | Batch 360/383 | Cost: 0.8753\n",
            "Epoch: 013/025 Train Acc.: 81.08% | Validation Acc.: 74.80%\n",
            "Time elapsed: 16.70 min\n",
            "Epoch: 014/025 | Batch 000/383 | Cost: 0.4325\n",
            "Epoch: 014/025 | Batch 120/383 | Cost: 0.5298\n",
            "Epoch: 014/025 | Batch 240/383 | Cost: 0.5962\n",
            "Epoch: 014/025 | Batch 360/383 | Cost: 0.6495\n",
            "Epoch: 014/025 Train Acc.: 85.73% | Validation Acc.: 75.50%\n",
            "Time elapsed: 17.99 min\n",
            "Epoch: 015/025 | Batch 000/383 | Cost: 0.4743\n",
            "Epoch: 015/025 | Batch 120/383 | Cost: 0.4527\n",
            "Epoch: 015/025 | Batch 240/383 | Cost: 0.3980\n",
            "Epoch: 015/025 | Batch 360/383 | Cost: 0.4704\n",
            "Epoch: 015/025 Train Acc.: 87.51% | Validation Acc.: 75.80%\n",
            "Time elapsed: 19.27 min\n",
            "Epoch: 016/025 | Batch 000/383 | Cost: 0.3573\n",
            "Epoch: 016/025 | Batch 120/383 | Cost: 0.5161\n",
            "Epoch: 016/025 | Batch 240/383 | Cost: 0.8183\n",
            "Epoch: 016/025 | Batch 360/383 | Cost: 0.5599\n",
            "Epoch: 016/025 Train Acc.: 84.63% | Validation Acc.: 73.50%\n",
            "Time elapsed: 20.55 min\n",
            "Epoch: 017/025 | Batch 000/383 | Cost: 0.3803\n",
            "Epoch: 017/025 | Batch 120/383 | Cost: 1.0083\n",
            "Epoch: 017/025 | Batch 240/383 | Cost: 0.6728\n",
            "Epoch: 017/025 | Batch 360/383 | Cost: 0.5373\n",
            "Epoch: 017/025 Train Acc.: 87.59% | Validation Acc.: 75.90%\n",
            "Time elapsed: 21.84 min\n",
            "Epoch: 018/025 | Batch 000/383 | Cost: 0.3428\n",
            "Epoch: 018/025 | Batch 120/383 | Cost: 0.3178\n",
            "Epoch: 018/025 | Batch 240/383 | Cost: 0.3678\n",
            "Epoch: 018/025 | Batch 360/383 | Cost: 0.4563\n",
            "Epoch: 018/025 Train Acc.: 91.10% | Validation Acc.: 75.30%\n",
            "Time elapsed: 23.13 min\n",
            "Epoch: 019/025 | Batch 000/383 | Cost: 0.2925\n",
            "Epoch: 019/025 | Batch 120/383 | Cost: 0.2200\n",
            "Epoch: 019/025 | Batch 240/383 | Cost: 0.3575\n",
            "Epoch: 019/025 | Batch 360/383 | Cost: 0.2210\n",
            "Epoch: 019/025 Train Acc.: 93.76% | Validation Acc.: 74.90%\n",
            "Time elapsed: 24.41 min\n",
            "Epoch: 020/025 | Batch 000/383 | Cost: 0.1384\n",
            "Epoch: 020/025 | Batch 120/383 | Cost: 0.3544\n",
            "Epoch: 020/025 | Batch 240/383 | Cost: 0.5099\n",
            "Epoch: 020/025 | Batch 360/383 | Cost: 0.2977\n",
            "Epoch: 020/025 Train Acc.: 93.00% | Validation Acc.: 77.70%\n",
            "Time elapsed: 25.69 min\n",
            "Epoch: 021/025 | Batch 000/383 | Cost: 0.2436\n",
            "Epoch: 021/025 | Batch 120/383 | Cost: 0.3992\n",
            "Epoch: 021/025 | Batch 240/383 | Cost: 0.6025\n",
            "Epoch: 021/025 | Batch 360/383 | Cost: 0.2882\n",
            "Epoch: 021/025 Train Acc.: 92.24% | Validation Acc.: 76.00%\n",
            "Time elapsed: 26.98 min\n",
            "Epoch: 022/025 | Batch 000/383 | Cost: 0.2165\n",
            "Epoch: 022/025 | Batch 120/383 | Cost: 0.2758\n",
            "Epoch: 022/025 | Batch 240/383 | Cost: 0.1705\n",
            "Epoch: 022/025 | Batch 360/383 | Cost: 0.3327\n",
            "Epoch: 022/025 Train Acc.: 95.40% | Validation Acc.: 77.40%\n",
            "Time elapsed: 28.26 min\n",
            "Epoch: 023/025 | Batch 000/383 | Cost: 0.1869\n",
            "Epoch: 023/025 | Batch 120/383 | Cost: 0.0938\n",
            "Epoch: 023/025 | Batch 240/383 | Cost: 0.2034\n",
            "Epoch: 023/025 | Batch 360/383 | Cost: 0.3387\n",
            "Epoch: 023/025 Train Acc.: 95.31% | Validation Acc.: 77.80%\n",
            "Time elapsed: 29.54 min\n",
            "Epoch: 024/025 | Batch 000/383 | Cost: 0.1274\n",
            "Epoch: 024/025 | Batch 120/383 | Cost: 0.1440\n",
            "Epoch: 024/025 | Batch 240/383 | Cost: 0.1691\n",
            "Epoch: 024/025 | Batch 360/383 | Cost: 0.1815\n",
            "Epoch: 024/025 Train Acc.: 96.22% | Validation Acc.: 76.30%\n",
            "Time elapsed: 30.82 min\n",
            "Epoch: 025/025 | Batch 000/383 | Cost: 0.0593\n",
            "Epoch: 025/025 | Batch 120/383 | Cost: 0.0517\n",
            "Epoch: 025/025 | Batch 240/383 | Cost: 0.1567\n",
            "Epoch: 025/025 | Batch 360/383 | Cost: 0.1563\n",
            "Epoch: 025/025 Train Acc.: 96.09% | Validation Acc.: 76.80%\n",
            "Time elapsed: 32.12 min\n",
            "Total Training Time: 32.12 min\n"
          ]
        }
      ],
      "source": [
        "def compute_accuracy(model, data_loader, device):\n",
        "    correct_pred, num_examples = 0, 0\n",
        "    for i, (features, targets) in enumerate(data_loader):\n",
        "\n",
        "        features = features.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        logits, probas = model(features)\n",
        "        _, predicted_labels = torch.max(probas, 1)\n",
        "        num_examples += targets.size(0)\n",
        "        correct_pred += (predicted_labels == targets).sum()\n",
        "    return correct_pred.float()/num_examples * 100\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# use random seed for reproducibility (here batch shuffling)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
        "\n",
        "        ### PREPARE MINIBATCH\n",
        "        features = features.to(DEVICE)\n",
        "        targets = targets.to(DEVICE)\n",
        "\n",
        "        ### FORWARD AND BACK PROP\n",
        "        logits, probas = model(features)\n",
        "        cost = F.cross_entropy(logits, targets)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        cost.backward()\n",
        "\n",
        "        ### UPDATE MODEL PARAMETERS\n",
        "        optimizer.step()\n",
        "\n",
        "        ### LOGGING\n",
        "        if not batch_idx % 120:\n",
        "            print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
        "                   f'Batch {batch_idx:03d}/{len(train_loader):03d} |'\n",
        "                   f' Cost: {cost:.4f}')\n",
        "\n",
        "    # no need to build the computation graph for backprop when computing accuracy\n",
        "    with torch.set_grad_enabled(False):\n",
        "        train_acc = compute_accuracy(model, train_loader, device=DEVICE)\n",
        "        valid_acc = compute_accuracy(model, valid_loader, device=DEVICE)\n",
        "        print(f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} Train Acc.: {train_acc:.2f}%'\n",
        "              f' | Validation Acc.: {valid_acc:.2f}%')\n",
        "\n",
        "    elapsed = (time.time() - start_time)/60\n",
        "    print(f'Time elapsed: {elapsed:.2f} min')\n",
        "\n",
        "elapsed = (time.time() - start_time)/60\n",
        "print(f'Total Training Time: {elapsed:.2f} min')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzQMWKq5j5xE",
        "outputId": "e653fac4-af01-439a-e3bc-af9ff1282f28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 74.04%\n"
          ]
        }
      ],
      "source": [
        "with torch.set_grad_enabled(False): # save memory during inference\n",
        "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader, device=DEVICE)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "371px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}